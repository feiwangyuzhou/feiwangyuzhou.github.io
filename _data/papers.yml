  -
    layout: paper
    paper-type: article #changes display of reference in paper list
    year: 2015
    selected: yes
    title: >
      CODRA: A Novel Discriminative Framework for Rhetorical Analysis
    authors: Shafiq Joty, Giuseppe Carenini, and Raymond T Ng
    id: joty-carenini-ng-cl-15
    img: joty-carenini-ng-cl-15-fig
    slides: media/joty-carenini-ng-cl-15.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: journal
    pages: 385-435
    journal: Computational Linguistics
    doc-url: papers/joty-carenini-ng-cl-15
    abstract: >
      Clauses and sentences rarely stand on their own in an actual discourse; rather, the relationship between them carries important information that allows the discourse to express a meaning as a whole beyond the sum of its individual parts. Rhetorical analysis seeks to uncover this coherence structure. In this article, we present CODRA— a COmplete probabilistic Discriminative framework for performing Rhetorical Analysis in accordance with Rhetorical Structure Theory, which posits a tree representation of a discourse. CODRA comprises a discourse segmenter and a discourse parser. First, the discourse segmenter, which is based on a binary classifier, identifies the elementary discourse units in a given text. Then the discourse parser builds a discourse tree by applying an optimal parsing algorithm to probabilities inferred from two Conditional Random Fields: one for intra-sentential parsing and the other for multi-sentential parsing. We present two approaches to combine these two stages of parsing effectively. By conducting a series of empirical evaluations over two different data sets, we demonstrate that CODRA significantly outperforms the state-of-the-art, often by a wide margin. We also show that a reranking of the k-best parse hypotheses generated by CODRA can potentially improve the accuracy even further.
    bibtex: >
      @article{joty-carenini-ng-cl-15,
       abstract = {Clauses and sentences rarely stand on their own in an actual discourse; rather, the relationship
      between them carries important information that allows the discourse to express a meaning as a
      whole beyond the sum of its individual parts. Rhetorical analysis seeks to uncover this coherence
      structure. In this article, we present CODRA— a COmplete probabilistic Discriminative
      framework for performing Rhetorical Analysis in accordance with Rhetorical Structure Theory, which posits a tree representation of a discourse.
      CODRA comprises a discourse segmenter and a discourse parser. First, the discourse
      segmenter, which is based on a binary classifier, identifies the elementary discourse units in a
      given text. Then the discourse parser builds a discourse tree by applying an optimal parsing
      algorithm to probabilities inferred from two Conditional Random Fields: one for intra-sentential
      parsing and the other for multi-sentential parsing. We present two approaches to combine these
      two stages of parsing effectively. By conducting a series of empirical evaluations over two
      different data sets, we demonstrate that CODRA significantly outperforms the state-of-the-art, often by a wide margin. We also show that a reranking of the k-best parse hypotheses generated
      by CODRA can potentially improve the accuracy even further.},
       author = {Joty, Shafiq and Carenini, Giuseppe and Ng, Raymond T},
       journal = {Computational Linguistics},
       link = {papers/joty-carenini-ng-cl-15},
       pages = {385-435},
       publisher = {MIT Press},
       title = {CODRA: A Novel Discriminative Framework for Rhetorical Analysis},
       volume = {41:3},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2015
    selected: no
    title: >
      Pairwise Neural Machine Translation Evaluation
    authors: Francisco Guzmán, Shafiq Joty, Lluís Màrquez, and Preslav Nakov
    id: guzman-joty-marquez-nakov-acl-15
    img: guzman-joty-marquez-nakov-acl-15-fig
    slides: media/guzman-joty-marquez-nakov-acl-15.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 805-814
    booktitle: >
      Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and The 7th International Joint Conference of the Asian Federation of Natural Language Processing (ACL'15)
    doc-url: http://www.aclweb.org/anthology/P15-1078
    abstract: >
      We present a novel framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is compacted into relatively small distributed vector representations, and fed into a multi-layer neural network that models the interaction between each of the hypotheses and the reference, as well as between the two hypotheses. These compact representations are in turn based on word and sentence embeddings, which are learned using neural networks. The framework is flexible, allows for efficient learning and classification, and yields correlation with humans that rivals the state of the art.
    bibtex: >
      @inproceedings{guzman-joty-marquez-nakov-acl-15,
       abstract = {We present a novel framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is compacted into relatively small distributed vector representations, and fed into a multi-layer neural network that models the interaction between each of the hypotheses and the reference, as well as between the two hypotheses. These compact representations are in turn based on word and sentence embeddings, which are learned using neural networks. The framework is flexible, allows for efficient learning and classification, and yields correlation with humans that rivals the state of the art.},
       address = {Beijing, China},
       author = {Guzm\'{a}n, Francisco  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav},
       booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and The 7th International Joint Conference of the Asian
      Federation of Natural Language Processing},
       link = {http://www.aclweb.org/anthology/P15-1078},
       month = {July},
       pages = {805--814},
       publisher = {Association for Computational Linguistics},
       series = {ACL'15},
       title = {Pairwise Neural Machine Translation Evaluation},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2015
    selected: no
    title: >
      Thread-Level Information for Comment Classification in Community Question Answering
    authors: Alberto Barron-Cedeno, Simone Filice, Giovanni Da San Martino, Shafiq Joty, Lluís Màrquez, Preslav Nakov, and Alessandro Moschitti
    id: cedeno-et-al-acl-15
    img: cedeno-et-al-acl-15-fig
    slides: media/cedeno-et-al-acl-15.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 687-693
    booktitle: >
      Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL'15)
    doc-url: http://www.aclweb.org/anthology/P15-2113
    abstract: >
      Community Question Answering (cQA) is a new application of QA in social contexts (e.g., fora). It presents new interesting challenges and research directions, e.g., exploiting the dependencies between the different comments of a thread to select the best answer for a given question. In this paper, we explored two ways of modeling such dependencies: (i) by designing specific features looking globally at the thread; and (ii) by applying structure prediction models. We trained and evaluated our models on data from SemEval-2015 Task 3 on Answer Selection in cQA. Our experiments show that: (i) the thread-level features consistently improve the performance for a variety of machine learning models, yielding state-of-the-art results; and (ii) sequential dependencies between the answer labels captured by structured prediction models are not enough to improve the results, indicating that more information is needed in the joint model.
    bibtex: >
      @inproceedings{cedeno-et-al-acl-15,
       abstract = {Community Question Answering (cQA) is
      a new application of QA in social contexts
      (e.g., fora). It presents new interesting
      challenges and research directions, e.g., exploiting the dependencies between the
      different comments of a thread to select
      the best answer for a given question. In
      this paper, we explored two ways of modeling
      such dependencies: (i) by designing
      specific features looking globally at the
      thread; and (ii) by applying structure prediction
      models. We trained and evaluated
      our models on data from SemEval-2015
      Task 3 on Answer Selection in cQA. Our
      experiments show that: (i) the thread-level
      features consistently improve the performance
      for a variety of machine learning
      models, yielding state-of-the-art results;
      and (ii) sequential dependencies between
      the answer labels captured by structured
      prediction models are not enough to improve
      the results, indicating that more information
      is needed in the joint model.},
       address = {Beijing, China},
       author = {Barron-Cedeno, Alberto  and  Filice, Simone  and  Da San Martino, Giovanni  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav  and  Moschitti, Alessandro},
       booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing},
       link = {http://www.aclweb.org/anthology/P15-2113},
       month = {July},
       pages = {687--693},
       publisher = {Association for Computational Linguistics},
       series = {ACL'15},
       title = {Thread-Level Information for Comment Classification in Community Question Answering},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2015
    selected: no
    title: >
      Using Joint Models for Domain Adaptation in Statistical Machine Translation
    authors: Nadir Durrani, Hassan Sajjad, Shafiq Joty, Ahmed Abdelali, and Stephan Vogel
    id: durrani-et-al-amta-15
    img: durrani-et-al-amta-15-fig
    slides: media/durrani-et-al-amta-15.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 687-693
    booktitle: >
      Proceedings of the Association for Machine Translation in the Americas (AMTA'15)
    doc-url: papers/durrani-et-al-amta-15
    abstract: >
      Joint models have recently shown to improve the state-of-the-art in machine translation (MT). We apply EM-based mixture modeling and data selection techniques using two joint models, namely the Operation Sequence Model or OSM — an ngram-based translation and reordering model, and the Neural Network Joint Model or NNJM — a continuous space translation model, to carry out domain adaptation for MT. The diversity of the two models, OSM with inherit reordering information and NNJM with continuous space modeling makes them interesting to be explored for this task. Our contribution in this paper is fusing the existing known techniques (linear interpolation, cross-entropy) with the state-of-the-art MT models (OSM, NNJM). On a standard task of translating German-to-English and Arabic-to-English IWSLT TED talks, we observed statistically significant improvements of up to +0.9 BLEU points.
    bibtex: >
      @inproceedings{durrani-et-al-amta-15,
       abstract = {Joint models have recently shown to improve the state-of-the-art in machine translation (MT).
      We apply EM-based mixture modeling and data selection techniques using two joint models, namely the Operation Sequence Model or OSM — an ngram-based translation and reordering
      model, and the Neural Network Joint Model or NNJM — a continuous space translation model, to carry out domain adaptation for MT. The diversity of the two models, OSM with inherit
      reordering information and NNJM with continuous space modeling makes them interesting to
      be explored for this task. Our contribution in this paper is fusing the existing known techniques
      (linear interpolation, cross-entropy) with the state-of-the-art MT models (OSM, NNJM). On a
      standard task of translating German-to-English and Arabic-to-English IWSLT TED talks, we
      observed statistically significant improvements of up to +0.9 BLEU points.},
       address = {Florida, USA},
       author = {Nadir Durrani and Hassan Sajjad and Shafiq Joty and Ahmed Abdelali and Stephan Vogel},
       booktitle = {Proceedings of the Association for Machine Translation in the Americas},
       link = {papers/durrani-et-al-amta-15},
       month = {November},
       pages = {687--693},
       series = {AMTA'15},
       title = {Using Joint Models for Domain Adaptation in Statistical Machine Translation},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2015
    selected: no
    title: >
      How to Avoid Unwanted Pregnancies: Domain Adaptation using Neural Network Models
    authors: Shafiq Joty, Hassan Sajjad, Nadir Durrani, Kamla Al-Mannai, Ahmed Abdelali, and Stephan Vogel
    id: joty-et-al-emnlp-15-1
    img: joty-et-al-emnlp-15-1-fig
    slides: media/joty-et-al-emnlp-15-1.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 1259-1270
    booktitle: >
      Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP'15)
    doc-url: http://aclweb.org/anthology/D15-1147
    abstract: >
      We present novel models for domain adaptation based on the neural network joint model (NNJM). Our models maximize the cross entropy by regularizing the loss function with respect to in-domain model. Domain adaptation is carried out by assigning higher weight to out-domain sequences that are similar to the in-domain data. In our alternative model we take a more restrictive approach by additionally penalizing sequences similar to the outdomain data. Our models achieve better perplexities than the baseline NNJM models and give improvements of up to 0.5 and 0.6 BLEU points in Arabic-to-English and English-to-German language pairs, on a standard task of translating TED talks.
    bibtex: >
      @inproceedings{joty-et-al-emnlp-15-1,
       abstract = {We present novel models for domain adaptation
      based on the neural network joint
      model (NNJM). Our models maximize
      the cross entropy by regularizing the loss
      function with respect to in-domain model.
      Domain adaptation is carried out by assigning
      higher weight to out-domain sequences
      that are similar to the in-domain
      data. In our alternative model we take a
      more restrictive approach by additionally
      penalizing sequences similar to the outdomain
      data. Our models achieve better
      perplexities than the baseline NNJM models
      and give improvements of up to 0.5
      and 0.6 BLEU points in Arabic-to-English
      and English-to-German language pairs, on
      a standard task of translating TED talks.},
       address = {Lisbon, Portugal},
       author = {Joty, Shafiq  and  Sajjad, Hassan  and  Durrani, Nadir  and  Al-Mannai, Kamla  and  Abdelali, Ahmed  and  Vogel, Stephan},
       booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
       link = {http://aclweb.org/anthology/D15-1147},
       pages = {1259--1270},
       publisher = {ACL},
       series = {EMNLP'15},
       title = {How to Avoid Unwanted Pregnancies: Domain Adaptation using Neural Network Models},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2015
    selected: no
    title: >
      Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings
    authors: Pengfei Liu, Shafiq Joty, and Helen Meng
    id: liu-joty-meng-emnlp-15
    img: liu-joty-meng-emnlp-15-fig
    slides: media/liu-joty-meng-emnlp-15.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 1433-1443
    booktitle: >
      Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP'15)
    doc-url: http://aclweb.org/anthology/D15-1168
    abstract: >
      The tasks in fine-grained opinion mining can be regarded as either a token-level sequence labeling problem or as a semantic compositional task. We propose a general class of discriminative models based on recurrent neural networks (RNNs) and word embeddings that can be successfully applied to such tasks without any taskspecific feature engineering effort. Our experimental results on the task of opinion target identification show that RNNs, without using any hand-crafted features, outperform feature-rich CRF-based models. Our framework is flexible, allows us to incorporate other linguistic features, and achieves results that rival the top performing systems in SemEval-2014.
    bibtex: >
      @inproceedings{liu-joty-meng-emnlp-15,
       abstract = {The tasks in fine-grained opinion mining
      can be regarded as either a token-level sequence
      labeling problem or as a semantic
      compositional task. We propose a general
      class of discriminative models based
      on recurrent neural networks (RNNs) and
      word embeddings that can be successfully
      applied to such tasks without any taskspecific
      feature engineering effort. Our
      experimental results on the task of opinion
      target identification show that RNNs, without using any hand-crafted features, outperform feature-rich CRF-based models.
      Our framework is flexible, allows us to
      incorporate other linguistic features, and
      achieves results that rival the top performing
      systems in SemEval-2014.},
       address = {Lisbon, Portugal},
       author = {Liu, Pengfei  and  Joty, Shafiq  and  Meng, Helen},
       booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
       link = {http://aclweb.org/anthology/D15-1168},
       pages = {1433--1443},
       publisher = {ACL},
       series = {EMNLP'15},
       title = {Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2015
    selected: no
    title: >
      Global Thread-level Inference for Comment Classification in Community Question Answering
    authors: Shafiq Joty, Alberto Barron-Cedeno, Giovanni Da San Martino, Simone Filice, Lluís Màrquez, Alessandro Moschitti, and Preslav Nakov
    id: joty-et-al-emnlp-15-2
    img: joty-et-al-emnlp-15-2-fig
    slides: media/joty-et-al-emnlp-15-2.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 573-578
    booktitle: >
      Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing
    doc-url: https://aclweb.org/anthology/D/D15/D15-1068
    abstract: >
      Community question answering, a recent evolution of question answering in the Web context, allows a user to quickly consult the opinion of a number of people on a particular topic, thus taking advantage of the wisdom of the crowd. Here we try to help the user by deciding automatically which answers are good and which are bad for a given question. In particular, we focus on exploiting the output structure at the thread level in order to make more consistent global decisions. More specifically, we exploit the relations between pairs of comments at any distance in the thread, which we incorporate in a graph-cut and in an ILP frameworks. We evaluated our approach on the benchmark dataset of SemEval-2015 Task 3. Results improved over the state of the art, confirming the importance of using thread level information.
    bibtex: >
      @inproceedings{joty-et-al-emnlp-15-2,
       abstract = {Community question answering, a recent
      evolution of question answering in the
      Web context, allows a user to quickly consult
      the opinion of a number of people on
      a particular topic, thus taking advantage
      of the wisdom of the crowd. Here we
      try to help the user by deciding automatically
      which answers are good and which
      are bad for a given question. In particular, we focus on exploiting the output structure
      at the thread level in order to make
      more consistent global decisions. More
      specifically, we exploit the relations between
      pairs of comments at any distance
      in the thread, which we incorporate in a
      graph-cut and in an ILP frameworks. We
      evaluated our approach on the benchmark
      dataset of SemEval-2015 Task 3. Results
      improved over the state of the art, confirming
      the importance of using thread level information.},
       address = {Lisbon, Portugal},
       author = {Joty, Shafiq  and  Barron-Cedeno, Alberto  and  Da San Martino, Giovanni  and  Filice, Simone  and  M\`{a}rquez, Llu\'{i}s  and  Moschitti, Alessandro  and  Nakov, Preslav},
       booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
       link = {https://aclweb.org/anthology/D/D15/D15-1068},
       pages = {573--578},
       publisher = {ACL},
       title = {Global Thread-level Inference for Comment Classification in Community Question Answering},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2015
    selected: no
    title: >
      QCRI: Answer Selection for Community Question Answering - Experiments for Arabic and English
    authors: Massimo Nicosia, Simone Filice, Alberto Barron-Cedeno, Iman Saleh, Hamdy Mubarak, Wei Gao, Preslav Nakov, Giovanni Da, Alessandro Moschitti, Kareem Darwish, Llu\'\is Màrquez, Shafiq R., and Walid Magdy
    id: nicosia-et-al-semeval-15
    img: nicosia-et-al-semeval-15-fig
    slides: media/nicosia-et-al-semeval-15.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 203-209
    booktitle: >
      Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval'15)
    doc-url: http://aclweb.org/anthology/S/S15/S15-2036.pdf
    abstract: >
      This paper describes QCRI’s participation in SemEval-2015 Task 3 “Answer Selection in Community Question Answering”, which targeted real-life Web forums, and was offered in both Arabic and English. We apply a supervised machine learning approach considering a manifold of features including among others word n-grams, text similarity, sentiment analysis, the presence of specific words, and the context of a comment. Our approach was the best performing one in the Arabic subtask and the third best in the two English subtasks.
    bibtex: >
      @inproceedings{nicosia-et-al-semeval-15,
       abstract = {This paper describes QCRI’s participation in
      SemEval-2015 Task 3 “Answer Selection in
      Community Question Answering”, which targeted
      real-life Web forums, and was offered
      in both Arabic and English. We apply a supervised
      machine learning approach considering
      a manifold of features including among others
      word n-grams, text similarity, sentiment analysis, the presence of specific words, and the
      context of a comment. Our approach was the
      best performing one in the Arabic subtask and
      the third best in the two English subtasks.},
       address = {Denver, Colorado, USA},
       author = {Massimo Nicosia and Simone Filice and Alberto Barron-Cedeno and Iman Saleh and Hamdy Mubarak and Wei Gao and Preslav Nakov and Giovanni Da San Martino and Alessandro Moschitti and Kareem Darwish and Llu\'{\i}s M\`{a}rquez and Shafiq R. Joty and Walid Magdy},
       booktitle = {Proceedings of the 9th International Workshop on Semantic Evaluation},
       link = {http://aclweb.org/anthology/S/S15/S15-2036.pdf},
       month = {June},
       pages = {203--209},
       series = {SemEval'15},
       title = {{QCRI:} Answer Selection for Community Question Answering - Experiments
      for Arabic and English},
       year = {2015}
      }
      
      
  -
    layout: paper
    paper-type: article #changes display of reference in paper list
    year: 2016
    selected: yes
    title: >
      Machine translation evaluation with neural networks
    authors: Francisco Guzmán, Shafiq Joty, Lluís Màrquez, and Preslav Nakov
    id: guzman-joty-marquez-nakov-csl-16
    img: guzman-joty-marquez-nakov-csl-16-fig
    slides: media/guzman-joty-marquez-nakov-csl-16.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: journal
    pages: 180-200
    journal: Computer Speech & Language
    doc-url: http://www.sciencedirect.com/science/article/pii/S0885230816301693
    abstract: >
      Abstract We present a framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is embedded into compact distributed vector representations, and fed into a multi-layer neural network that models nonlinear interactions between each of the hypotheses and the reference, as well as between the two hypotheses. We experiment with the benchmark datasets from the \WMT\ Metrics shared task, on which we obtain the best results published so far, with the basic network configuration. We also perform a series of experiments to analyze and understand the contribution of the different components of the network. We evaluate variants and extensions, including fine-tuning of the semantic embeddings, and sentence-based representations modeled with convolutional and recurrent neural networks. In summary, the proposed framework is flexible and generalizable, allows for efficient learning and scoring, and provides an \MT\ evaluation metric that correlates with human judgments, and is on par with the state of the art.
    bibtex: >
      @article{guzman-joty-marquez-nakov-csl-16,
       abstract = {Abstract We present a framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation.
      In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses
      is embedded into compact distributed vector representations, and fed into a multi-layer neural network that
      models nonlinear interactions between each of the hypotheses and the reference, as well as between the two hypotheses.
      We experiment with the benchmark datasets from the \{WMT\} Metrics shared task, on which we obtain the best results published so far, with the basic network configuration.
      We also perform a series of experiments to analyze and understand the contribution of the different components of the network.
      We evaluate variants and extensions, including fine-tuning of the semantic embeddings, and sentence-based representations modeled with
      convolutional and recurrent neural networks. In summary, the proposed framework is flexible and generalizable, allows for efficient learning and scoring, and provides an \{MT\} evaluation metric that correlates with human judgments, and is on par with the state of the art.},
       author = {Guzm\'{a}n, Francisco  and Joty, Shafiq  and Màrquez, Lluís  and Nakov, Preslav},
       doi = {http://dx.doi.org/10.1016/j.csl.2016.12.005},
       issn = {0885-2308},
       journal = {Computer Speech & Language},
       link = {http://www.sciencedirect.com/science/article/pii/S0885230816301693},
       pages = {180--200},
       title = {Machine translation evaluation with neural networks},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: article #changes display of reference in paper list
    year: 2016
    selected: yes
    title: >
      Sleep Quality Prediction From Wearable Data Using Deep Learning
    authors: Aarti Sathyanarayana, Shafiq Joty, Luis Fernandez-Luque, Ferda Ofli, Jaideep Srivastava, Ahmed Elmagarmid, Shahrad Taheri, and Teresa Arora
    id: sathyanarayana-et-al-jmu-16
    img: sathyanarayana-et-al-jmu-16-fig
    slides: media/sathyanarayana-et-al-jmu-16.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: journal
    journal: JMIR mHealth and uHealth (JMU)
    doc-url: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5116102/
    abstract: >
      BACKGROUND: The importance of sleep is paramount to health. Insufficient sleep can reduce physical, emotional, and mental well-being and can lead to a multitude of health complications among people with chronic conditions. Physical activity and sleep are highly interrelated health behaviors. Our physical activity during the day (ie, awake time) influences our quality of sleep, and vice versa. The current popularity of wearables for tracking physical activity and sleep, including actigraphy devices, can foster the development of new advanced data analytics. This can help to develop new electronic health (eHealth) applications and provide more insights into sleep science. OBJECTIVE: The objective of this study was to evaluate the feasibility of predicting sleep quality (ie, poor or adequate sleep efficiency) given the physical activity wearable data during awake time. In this study, we focused on predicting good or poor sleep efficiency as an indicator of sleep quality. METHODS: Actigraphy sensors are wearable medical devices used to study sleep and physical activity patterns. The dataset used in our experiments contained the complete actigraphy data from a subset of 92 adolescents over 1 full week. Physical activity data during awake time was used to create predictive models for sleep quality, in particular, poor or good sleep efficiency. The physical activity data from sleep time was used for the evaluation. We compared the predictive performance of traditional logistic regression with more advanced deep learning methods: multilayer perceptron (MLP), convolutional neural network (CNN), simple Elman-type recurrent neural network (RNN), long short-term memory (LSTM-RNN), and a time-batched version of LSTM-RNN (TB-LSTM). RESULTS: Deep learning models were able to predict the quality of sleep (ie, poor or good sleep efficiency) based on wearable data from awake periods. More specifically, the deep learning methods performed better than traditional logistic regression. “CNN had the highest specificity and sensitivity, and an overall area under the receiver operating characteristic (ROC) curve (AUC) of 0.9449, which was 46% better as compared with traditional logistic regression (0.6463). CONCLUSIONS: Deep learning methods can predict the quality of sleep based on actigraphy data from awake periods. These predictive models can be an important tool for sleep research and to improve eHealth solutions for sleep.
    bibtex: >
      @article{sathyanarayana-et-al-jmu-16,
       abstract = {BACKGROUND:
      The importance of sleep is paramount to health. Insufficient sleep can reduce physical, emotional, and mental well-being and can lead to a multitude of health complications among people with chronic conditions. Physical activity and sleep are highly interrelated health behaviors. Our physical activity during the day (ie, awake time) influences our quality of sleep, and vice versa. The current popularity of wearables for tracking physical activity and sleep, including actigraphy devices, can foster the development of new advanced data analytics. This can help to develop new electronic health (eHealth) applications and provide more insights into sleep science.
      OBJECTIVE:
      The objective of this study was to evaluate the feasibility of predicting sleep quality (ie, poor or adequate sleep efficiency) given the physical activity wearable data during awake time. In this study, we focused on predicting good or poor sleep efficiency as an indicator of sleep quality.
      METHODS:
      Actigraphy sensors are wearable medical devices used to study sleep and physical activity patterns. The dataset used in our experiments contained the complete actigraphy data from a subset of 92 adolescents over 1 full week. Physical activity data during awake time was used to create predictive models for sleep quality, in particular, poor or good sleep efficiency. The physical activity data from sleep time was used for the evaluation. We compared the predictive performance of traditional logistic regression with more advanced deep learning methods: multilayer perceptron (MLP), convolutional neural network (CNN), simple Elman-type recurrent neural network (RNN), long short-term memory (LSTM-RNN), and a time-batched version of LSTM-RNN (TB-LSTM).
      RESULTS:
      Deep learning models were able to predict the quality of sleep (ie, poor or good sleep efficiency) based on wearable data from awake periods. More specifically, the deep learning methods performed better than traditional logistic regression. “CNN had the highest specificity and sensitivity, and an overall area under the receiver operating characteristic (ROC) curve (AUC) of 0.9449, which was 46% better as compared with traditional logistic regression (0.6463).
      CONCLUSIONS:
      Deep learning methods can predict the quality of sleep based on actigraphy data from awake periods. These predictive models can be an important tool for sleep research and to improve eHealth solutions for sleep.},
       author = {Aarti Sathyanarayana and Shafiq Joty and Luis Fernandez-Luque and Ferda Ofli and Jaideep Srivastava and Ahmed Elmagarmid and Shahrad Taheri and Teresa Arora},
       doi = {10.2196/mhealth.6562},
       journal = {JMIR mHealth and uHealth (JMU)},
       link = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5116102/},
       number = {e125},
       pmid = {27815231},
       title = {Sleep Quality Prediction From Wearable Data Using Deep Learning},
       volume = {4(4)},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2016
    selected: no
    title: >
      Speech Act Modeling of Written Asynchronous Conversations with Task-Specific Embeddings and Conditional Structured Models
    authors: Shafiq Joty, and Enamul Hoque
    id: joty-hoque-acl-16
    img: joty-hoque-acl-16-fig
    slides: media/joty-hoque-acl-16.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 1746-1756
    booktitle: >
      Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL'16)
    doc-url: papers/joty-hoque-acl-16.pdf
    abstract: >
      This paper addresses the problem of speech act recognition in written asynchronous conversations (e.g., fora, emails). We propose a class of conditional structured models defined over arbitrary graph structures to capture the conversational dependencies between sentences. Our models use sentence representations encoded by a long short term memory (LSTM) recurrent neural model. Empirical evaluation shows the effectiveness of our approach over existing ones: (i) LSTMs provide better task-specific representations, and (ii) the global joint model improves over local models.
    bibtex: >
      @inproceedings{joty-hoque-acl-16,
       abstract = {This paper addresses the problem of
      speech act recognition in written asynchronous
      conversations (e.g., fora, emails). We propose a class of conditional
      structured models defined over arbitrary
      graph structures to capture the conversational
      dependencies between sentences.
      Our models use sentence representations
      encoded by a long short term memory
      (LSTM) recurrent neural model. Empirical
      evaluation shows the effectiveness
      of our approach over existing ones:
      (i) LSTMs provide better task-specific
      representations, and (ii) the global joint
      model improves over local models.},
       address = {Berlin, Germany},
       author = {Shafiq Joty and Enamul Hoque},
       booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics},
       link = {papers/joty-hoque-acl-16.pdf},
       numpages = {9},
       pages = {1746--1756},
       publisher = {ACL},
       series = {ACL'16},
       title = {Speech Act Modeling of Written Asynchronous Conversations with Task-Specific Embeddings and Conditional Structured Models},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2016
    selected: no
    title: >
      Joint Learning with Global Inference for Comment Classification in Community Question Answering
    authors: Shafiq Joty, Lluís Màrquez, and Preslav Nakov
    id: joty-marquez-nakov-naacl-16
    img: joty-marquez-nakov-naacl-16-fig
    slides: media/joty-marquez-nakov-naacl-16.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 703–-713
    booktitle: >
      Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL'16)
    doc-url: papers/joty-marquez-nakov-naacl-16.pdf
    bibtex: >
      @inproceedings{joty-marquez-nakov-naacl-16,
       address = {San Diego, California},
       author = {Shafiq Joty and  M\`{a}rquez, Llu\'{i}s and Preslav Nakov},
       booktitle = {Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
       numpages = {9},
       pages = {703–-713},
       publisher = {{ACL}
      abstract = {This paper addresses the problem of comment
      classification in community Question Answering.
      Following the state of the art, we approach
      the task with a global inference process
      to exploit the information of all comments
      in the answer-thread in the form of a
      fully connected graph. Our contribution comprises
      two novel joint learning models that are
      on-line and integrate inference within learning.
      The first one jointly learns two node- and
      edge-level MaxEnt classifiers with stochastic
      gradient descent and integrates the inference
      step with loopy belief propagation. The second
      model is an instance of fully connected
      pairwise CRFs (FCCRF). The FCCRF model
      significantly outperforms all other approaches
      and yields the best results on the task to date.
      Crucial elements for its success are the global
      normalization and an Ising-like edge potential.}},
       series = {NAACL'16},
       title = {Joint Learning with Global Inference for Comment Classification in Community Question Answering},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2016
    selected: no
    title: >
      A Deep Fusion Model for Domain Adaptation in Phrase-based MT
    authors: Nadir Durrani, Hassan Sajjad, Shafiq Joty, and Ahmed Abdelali
    id: durrani-sajjad-joty-abdelali-coling-16
    img: durrani-sajjad-joty-abdelali-coling-16-fig
    slides: media/durrani-sajjad-joty-abdelali-coling-16.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 3177-3187
    booktitle: >
      Proceedings of the 26th International Conference on Computational Linguistics, Proceedings of the Conference month     = December (COLING'16)
    doc-url: http://aclweb.org/anthology/C/C16/C16-1299.pdf
    abstract: >
      We present a novel fusion model for domain adaptation in Statistical Machine Translation. Our model is based on the joint source-target neural network (Devlin et al., 2014), and is learned by fusing in- and out-domain models. The adaptation is performed by backpropagating errors from the output layer to the word embedding layer of each model, subsequently adjusting parameters of the composite model towards the in-domain data. On the standard tasks of translating English-to-German and Arabic-to-English TED talks, we observed average improvements of +0.9 and +0.7 BLEU points, respectively over a competition grade phrase-based system. We also demonstrate improvements over existing adaptation methods.
    bibtex: >
      @inproceedings{durrani-sajjad-joty-abdelali-coling-16,
       abstract = {We present a novel fusion model for domain adaptation in Statistical Machine Translation. Our model is based on the joint source-target neural network (Devlin et al., 2014), and is learned
      by fusing in- and out-domain models. The adaptation is performed by backpropagating errors
      from the output layer to the word embedding layer of each model, subsequently adjusting parameters
      of the composite model towards the in-domain data. On the standard tasks of translating
      English-to-German and Arabic-to-English TED talks, we observed average improvements of
      +0.9 and +0.7 BLEU points, respectively over a competition grade phrase-based system. We also
      demonstrate improvements over existing adaptation methods.},
       address = {Osaka, Japan},
       author = {Nadir Durrani and
      Hassan Sajjad and
      Shafiq Joty and
      Ahmed Abdelali},
       booktitle = {{Proceedings of the 26th International Conference on Computational Linguistics, Proceedings of the Conference}
      month     = {December}},
       link = {http://aclweb.org/anthology/C/C16/C16-1299.pdf},
       pages = {3177--3187},
       series = {COLING'16},
       title = {A Deep Fusion Model for Domain Adaptation in Phrase-based {MT}},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2016
    selected: no
    title: >
      An Interactive System for Exploring Community Question Answering Forums
    authors: Enamul Hoque, Shafiq Joty, Lluís Màrquez, Alberto Barron-Cedeno, Giovanni Da San Martino, Alessandro Moschitti, Preslav Nakov, Salvatore Romeo, and Giuseppe Carenini
    id: hoque-et-al-coling-16-demo
    img: hoque-et-al-coling-16-demo-fig
    slides: media/hoque-et-al-coling-16-demo.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 1-5
    booktitle: >
      Proceedings of the 26th International Conference on Computational Linguistics: System Demonstrations (COLING'16)
    doc-url: http://aclweb.org/anthology/C16-2001
    abstract: >
      We present an interactive system to provide effective and efficient search capabilities in Community Question Answering (cQA) forums. The system integrates state-of-the-art technology for answer search with a Web-based user interface specifically tailored to support the cQA forum readers. The answer search module automatically finds relevant answers for a new question by exploring related questions and the comments within their threads. The graphical user interface presents the search results and supports the exploration of related information. The system is running live as a part of the Qatar Living forums.
    bibtex: >
      @inproceedings{hoque-et-al-coling-16-demo,
       abstract = {We present an interactive system to provide effective and efficient search capabilities in Community Question Answering (cQA) forums. The system integrates state-of-the-art technology for
      answer search with a Web-based user interface specifically tailored to support the cQA forum
      readers. The answer search module automatically finds relevant answers for a new question by
      exploring related questions and the comments within their threads. The graphical user interface
      presents the search results and supports the exploration of related information. The system is
      running live as a part of the Qatar Living forums.},
       address = {Osaka, Japan},
       author = {Hoque, Enamul  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Barron-Cedeno, Alberto  and  Da San Martino, Giovanni  and  Moschitti, Alessandro  and  Nakov, Preslav  and  Romeo, Salvatore  and  Carenini, Giuseppe},
       booktitle = {Proceedings of the 26th International Conference on Computational Linguistics: System Demonstrations},
       link = {http://aclweb.org/anthology/C16-2001},
       month = {December},
       pages = {1--5},
       publisher = {The COLING 2016 Organizing Committee},
       series = {COLING'16},
       title = {An Interactive System for Exploring Community Question Answering Forums},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2016
    selected: no
    title: >
      ConvKN at SemEval-2016 Task 3: Answer and Question Selection for Question Answering on Arabic and English Fora
    authors: Alberto Barron-Codeno, Giovanni Da San Martino, Shafiq Joty, Alessandro Moschitti, Fahad Al-Obaidli, Salvatore Romeo, Kateryna Tymoshenko, and Antonio Uva
    id: cedeno-et-al-semeval-16
    img: cedeno-et-al-semeval-16-fig
    slides: media/cedeno-et-al-semeval-16.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 896-903
    booktitle: >
      Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)
    doc-url: http://www.aclweb.org/anthology/S16-1138
    abstract: >
      We describe our system, ConvKN, participating to the SemEval-2016 Task 3 " Community Question Answering ". The task targeted the reranking of questions and comments in real-life web fora both in English and Arabic. ConvKN combines convolutional tree kernels with convolutional neural networks and additional manually designed features including text similarity and thread specific features. For the first time, we applied tree kernels to syntactic trees of Arabic sentences for a reranking task. Our approaches obtained the second best results in three out of four tasks. The only task we performed averagely is the one where we did not use tree kernels in our classifier.
    bibtex: >
      @inproceedings{cedeno-et-al-semeval-16,
       abstract = {We describe our system, ConvKN, participating to the SemEval-2016 Task 3 " Community Question Answering ". The task targeted the reranking of questions and comments in real-life web fora both in English and Arabic. ConvKN combines convolutional tree kernels with convolutional neural networks and additional manually designed features including text similarity and thread specific features. For the first time, we applied tree kernels to syntactic trees of Arabic sentences for a reranking task. Our approaches obtained the second best results in three out of four tasks. The only task we performed averagely is the one where we did not use tree kernels in our classifier.},
       address = {San Diego, California},
       author = {Barron-Codeno, Alberto  and  Da San Martino, Giovanni  and  Joty, Shafiq  and  Moschitti, Alessandro  and  Al-Obaidli, Fahad  and  Romeo, Salvatore  and  Tymoshenko, Kateryna  and  Uva, Antonio},
       booktitle = {Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)},
       link = {http://www.aclweb.org/anthology/S16-1138},
       month = {June},
       pages = {896--903},
       publisher = {Association for Computational Linguistics},
       title = {ConvKN at SemEval-2016 Task 3: Answer and Question Selection for Question Answering on Arabic and English Fora},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2016
    selected: no
    title: >
      Applications of Online Deep Learning for Crisis Response Using Social Media Information
    authors: Dat Tien, Shafiq R., Muhammad Imran, Hassan Sajjad, and Prasenjit Mitra
    id: nguyen-et-al-swdm-16
    img: nguyen-et-al-swdm-16-fig
    slides: media/nguyen-et-al-swdm-16.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    journal: CoRR
    doc-url: http://arxiv.org/abs/1610.01030
    abstract: >
      During natural or man-made disasters, humanitarian response organizations look for useful information to support their decision-making processes. Social media platforms such as Twitter have been considered as a vital source of useful information for disaster response and management. Despite advances in natural language processing techniques, processing short and informal Twitter messages is a challenging task. In this paper, we propose to use Deep Neural Network (DNN) to address two types of information needs of response organizations: 1) identifying informative tweets and 2) classifying them into topical classes. DNNs use distributed representation of words and learn the representation as well as higher level features automatically for the classification task. We propose a new online algorithm based on stochastic gradient descent to train DNNs in an online fashion during disaster situations. We test our models using a crisis-related real-world Twitter dataset.
    bibtex: >
      @inproceedings{nguyen-et-al-swdm-16,
       abstract = {During natural or man-made disasters, humanitarian response organizations look for useful information to support their decision-making processes. Social media platforms such as Twitter have been considered as a vital source of useful information for disaster response and management. Despite advances in natural language processing techniques, processing short and informal Twitter messages is a challenging task. In this paper, we propose to use Deep Neural Network (DNN) to address two types of information needs of response organizations: 1) identifying informative tweets and 2) classifying them into topical classes. DNNs use distributed representation of words and learn the representation as well as higher level features automatically for the classification task. We propose a new online algorithm based on stochastic gradient descent to train DNNs in an online fashion during disaster situations. We test our models using a crisis-related real-world Twitter dataset.},
       author = {Dat Tien Nguyen and
      Shafiq R. Joty and
      Muhammad Imran and
      Hassan Sajjad and
      Prasenjit Mitra},
       journal = {CoRR},
       link = {http://arxiv.org/abs/1610.01030},
       title = {Applications of Online Deep Learning for Crisis Response Using Social
      Media Information},
       volume = {abs/1610.01030},
       year = {2016}
      }
      
      
  -
    layout: paper
    paper-type: article #changes display of reference in paper list
    year: 2017
    selected: yes
    title: >
      Discourse Structure in Machine Translation Evaluation
    authors: Shafiq Joty, Francisco Guzmán, Lluís Màrquez, and Preslav Nakov
    id: joty-guzman-marquez-nakov-cl-17
    img: joty-guzman-marquez-nakov-cl-17-fig
    slides: media/joty-guzman-marquez-nakov-cl-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: journal
    pages: xx-xx
    journal: Computational Linguistics
    doc-url: papers/joty-guzman-marquez-nakov-cl-17.pdf
    abstract: >
      In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all- subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple linear combination with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment- and at the system-level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DISCOTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular, we show that (i) all aspects of the RST tree are relevant, (ii) nuclearity is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality.
    bibtex: >
      @article{joty-guzman-marquez-nakov-cl-17,
       abstract = {In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all- subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple linear combination with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment- and at the system-level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DISCOTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular, we show that (i) all aspects of the RST tree are relevant, (ii) nuclearity is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality.},
       author = {Shafiq Joty and Guzm\'{a}n, Francisco and Màrquez, Lluís and Preslav Nakov},
       journal = {Computational Linguistics},
       link = {papers/joty-guzman-marquez-nakov-cl-17.pdf},
       pages = {xx--xx},
       publisher = {MIT Press},
       title = {Discourse Structure in Machine Translation Evaluation},
       volume = {xx:x},
       year = {2017}
      }
      
      
  -
    layout: paper
    paper-type: article #changes display of reference in paper list
    year: 2017
    selected: yes
    title: >
      Domain Adaptation Using Neural Network Joint Model
    authors: Shafiq Joty, Nadir Durrani, Hassan Sajjad, and Ahmed Abdelali
    id: joty-durrani-sajjad-abdelali-csl-17
    img: joty-durrani-sajjad-abdelali-csl-17-fig
    slides: media/joty-durrani-sajjad-abdelali-csl-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: journal
    pages: 161-179
    journal: Computer Speech & Language
    doc-url: http://www.sciencedirect.com/science/article/pii/S0885230816301474
    abstract: >
      We explore neural joint models for the task of domain adaptation in machine translation in two ways: (i) we apply state-of-the-art domain adaptation techniques, such as mixture modelling and data selection using the recently proposed Neural Network Joint Model (NNJM) (Devlin et al., 2014); (ii) we propose two novel approaches to perform adaptation through instance weighting and weight readjustment in the NNJM framework. In our first approach, we propose a pair of models called Neural Domain Adaptation Models (NDAM) that minimizes the cross entropy by regularizing the loss function with respect to in-domain (and optionally to out-domain) model. In the second approach, we present a set of Neural Fusion Models (NFM) that combines the in- and the out-domain models by readjusting their parameters based on the in-domain data. We evaluated our models on the standard task of translating English-to-German and Arabic-to-English TED talks. The NDAM models achieved better perplexities and modest BLEU improvements compared to the baseline NNJM, trained either on in-domain or on a concatenation of in- and out-domain data. On the other hand, the NFM models obtained significant improvements of up to +0.9 and +0.7 BLEU points, respectively. We also demonstrate improvements over existing adaptation methods such as instance weighting, phrasetable fill-up, linear and log-linear interpolations.
    bibtex: >
      @article{joty-durrani-sajjad-abdelali-csl-17,
       abstract = {We explore neural joint models for the task of domain adaptation in machine translation in two ways: (i) we apply state-of-the-art domain adaptation techniques, such as mixture modelling and data selection using the recently proposed Neural Network Joint Model (NNJM) (Devlin et al., 2014); (ii) we propose two novel approaches to perform adaptation through instance weighting and weight readjustment in the NNJM framework. In our first approach, we propose a pair of models called Neural Domain Adaptation Models (NDAM) that minimizes the cross entropy by regularizing the loss function with respect to in-domain (and optionally to out-domain) model. In the second approach, we present a set of Neural Fusion Models (NFM) that combines the in- and the out-domain models by readjusting their parameters based on the in-domain data.
      We evaluated our models on the standard task of translating English-to-German and Arabic-to-English TED talks. The NDAM models achieved better perplexities and modest BLEU improvements compared to the baseline NNJM, trained either on in-domain or on a concatenation of in- and out-domain data. On the other hand, the NFM models obtained significant improvements of up to +0.9 and +0.7 BLEU points, respectively. We also demonstrate improvements over existing adaptation methods such as instance weighting, phrasetable fill-up, linear and log-linear interpolations.},
       author = {Shafiq Joty and Nadir Durrani and Hassan Sajjad and Ahmed Abdelali},
       doi = {https://doi.org/10.1016/j.csl.2016.12.006},
       issn = {0885-2308},
       journal = {Computer Speech & Language},
       link = {http://www.sciencedirect.com/science/article/pii/S0885230816301474},
       pages = {161-179},
       publisher = {Elsevier},
       title = {Domain Adaptation Using Neural Network Joint Model},
       volume = {45},
       year = {2017}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2017
    selected: no
    title: >
      A Neural Local Coherence Model
    authors: Dat Nguyen, and Shafiq Joty
    id: nguyen-joty-acl-17
    img: nguyen-joty-acl-17-fig
    slides: media/nguyen-joty-acl-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: xx-xx
    booktitle: >
      Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL'17)
    doc-url: papers/nguyen-joty-acl-17.pdf
    abstract: >
      We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.
    bibtex: >
      @inproceedings{nguyen-joty-acl-17,
       abstract = {We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.},
       address = {Vancouver, Canada},
       author = {Nguyen, Dat and Joty, Shafiq},
       booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics},
       link = {papers/nguyen-joty-acl-17.pdf},
       month = {August},
       pages = {xx--xx},
       publisher = {Association for Computational Linguistics},
       series = {ACL'17},
       title = {A Neural Local Coherence Model},
       year = {2017}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2017
    selected: no
    title: >
      Cross-language Learning with Adversarial Neural Networks: Application to Community Question Answering
    authors: Shafiq Joty, Preslav Nakov, Lluís Màrquez, and Israa Jaradat
    id: joty-nakov-marquez-jaradat-conll-17
    img: joty-nakov-marquez-jaradat-conll-17-fig
    slides: media/joty-nakov-marquez-jaradat-conll-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: xx-xx
    booktitle: >
      Proceedings of The SIGNLL Conference on Computational Natural Language Learning (CoNLL'17)
    doc-url: papers/joty-nakov-marquez-jaradat-conll-17.pdf
    abstract: >
      We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.
    bibtex: >
      @inproceedings{joty-nakov-marquez-jaradat-conll-17,
       abstract = {We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.},
       address = {Vancouver, Canada},
       author = {Shafiq Joty and Preslav Nakov and Lluís Màrquez and Israa Jaradat},
       booktitle = {Proceedings of The SIGNLL Conference on Computational Natural Language Learning},
       link = {papers/joty-nakov-marquez-jaradat-conll-17.pdf},
       month = {August},
       pages = {xx--xx},
       publisher = {Association for Computational Linguistics},
       series = {CoNLL'17},
       title = {Cross-language Learning with Adversarial Neural Networks: Application to Community Question Answering},
       year = {2017}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2017
    selected: no
    title: >
      CON-S2V: A Generic Framework for Incorporating Extra-Sentential Context into Sen2Vec
    authors: Tanay Kumar, Shafiq Joty, and Mohammad Al
    id: saha-joty-hasan-ecml-17
    img: saha-joty-hasan-ecml-17-fig
    slides: media/saha-joty-hasan-ecml-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: xx-xx
    booktitle: >
      Proceedings of The European Conference on Machine Learning & Principles and Practice of knowledge discovery in databases (ECML-PKDD'17)
    doc-url: papers/saha-joty-hasan-ecml-17.pdf
    abstract: >
      We present a novel approach to learn distributed representation of sentences from unlabeled data by modeling both content and context of a sentence. The content model learns sentence representation by predicting its words. On the other hand, the context model comprises a neighbor prediction component and a regularizer to model distributional and proximity hypotheses, respectively. We propose an online algorithm to train the model components jointly. We evaluate the models in a setup, where contextual information is available. The experimental results on tasks involving classification, clustering, and ranking of sentences show that our model outperforms the best existing models by a wide margin across multiple datasets.
    bibtex: >
      @inproceedings{saha-joty-hasan-ecml-17,
       abstract = {We present a novel approach to learn distributed representation of sentences from unlabeled data by modeling both content and context of a sentence. The content model learns sentence representation by predicting its words. On the other hand, the context model comprises a neighbor prediction component and a regularizer to model distributional and proximity hypotheses, respectively. We propose an online algorithm to train the model components jointly. We evaluate the models in a setup, where contextual information is available. The experimental results on tasks involving classification, clustering, and ranking of sentences show that our model outperforms the best existing models by a wide margin across multiple datasets.},
       address = {Macedonia, Skopje},
       author = {Tanay Kumar Saha and Shafiq Joty and Mohammad Al Hasan},
       booktitle = {Proceedings of The European Conference on Machine Learning &
      Principles and Practice of knowledge discovery in databases},
       link = {papers/saha-joty-hasan-ecml-17.pdf},
       month = {September},
       pages = {xx--xx},
       publisher = {Springer},
       series = {ECML-PKDD'17},
       title = {CON-S2V: A Generic Framework for Incorporating Extra-Sentential Context into Sen2Vec},
       year = {2017}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2017
    selected: no
    title: >
      Cross-Language Question Re-ranking
    authors: Giovanni Da, Salvatore Romeo, Alberto Barron-Cedeno, Lluís Màrquez Shafiq Joty, Alessandro Moschitti, and Preslav Nakov
    id: martino-et-al-sigir-17
    img: martino-et-al-sigir-17-fig
    slides: media/martino-et-al-sigir-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: xx-xx
    booktitle: >
      In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'17)
    doc-url: papers/martino-et-al-sigir-17.pdf
    abstract: >
      We study how to find relevant questions in community forums when the language of the query questions is different from that of the existing questions in the forum. In particular, we explore the Arabic-English language pair. We compare a kernel-based system with a feed-forward neural network in a scenario where a large parallel corpus is available for training a machine translation system, bilingual dictionaries, and cross-language word embeddings. We observe that both approaches degrade the performance of the system when working on the translated text, especially the kernel-based system, which depends heavily on a syntactic kernel. We address this issue using a cross-language tree kernel, which compares the original Arabic tree to the English trees of the forum questions. We show that this kernel almost closes the performance gap with respect to the monolingual system. On the neural network side, we use the parallel corpus to train cross-language embeddings, which we then use to represent the Arabic input and the English forum questions in the same space. The results also improve to close to those of the monolingual neural network. Overall, the kernel system shows a better performance compared to the neural network in all cases.
    bibtex: >
      @inproceedings{martino-et-al-sigir-17,
       abstract = {We study how to find relevant questions in community forums when the language of the query questions is different from that of the existing questions in the forum. In particular, we explore the Arabic--English language pair. We compare
      a kernel-based system with
      a feed-forward neural network in a scenario where a large parallel corpus is available for training a machine translation system, bilingual dictionaries, and cross-language word embeddings.
      We observe that both approaches degrade the performance of the system when working on the translated text, especially the kernel-based system, which depends heavily on a syntactic kernel.
      We address this issue using a cross-language tree kernel, which compares the original Arabic tree to the English trees of the forum questions. We show that this kernel almost closes the performance gap with respect to the monolingual system. On the neural network side, we use the parallel corpus to train cross-language embeddings, which we then use to represent the Arabic input and the English forum questions in the same space.
      The results also improve to close to those of the monolingual neural network. Overall, the kernel system shows a better performance compared to the neural network in all cases.},
       address = {Tokyo, Japan},
       author = {Giovanni Da San Martino and Salvatore Romeo and Alberto Barron-Cedeno and Shafiq Joty, Lluís Màrquez and Alessandro Moschitti and Preslav Nakov},
       booktitle = {In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
       link = {papers/martino-et-al-sigir-17.pdf},
       month = {September},
       pages = {xx--xx},
       publisher = {ACM},
       series = {SIGIR'17},
       title = {Cross-Language Question Re-ranking},
       year = {2017}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2017
    selected: no
    title: >
      Robust Classification of Crisis-Related Data on Social Networks Using Convolutional Neural Networks
    authors: Dat Nguyen, Kamela Ali, Shafiq Joty, Hassan Sajjad, Muhammad Imran, and Prasenjit Mitra
    id: nguyen-et-al-icwsm-17
    img: nguyen-et-al-icwsm-17-fig
    slides: media/nguyen-et-al-icwsm-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 632-635
    booktitle: >
      In Proceedings of the Eleventh International Conference on Web and Social Media (ICWSM'17)
    doc-url: papers/nguyen-et-al-icwsm-17.pdf
    abstract: >
      The role of social media, in particular microblogging platforms such as Twitter, as a conduit for actionable and tactical information during disasters is increasingly acknowledged. However, time-critical analysis of big crisis data on social media streams brings challenges to machine learning techniques, especially the ones that use supervised learning. The scarcity of labeled data, particularly in the early hours of a crisis, delays the learning process. Existing classification methods require a significant amount of labeled data specific to a particular event for training plus a lot of feature engineering to achieve best results. In this work, we introduce neural network based classification methods for identifying useful tweets during a crisis situation. At the onset of a disaster when no labeled data is available, our proposed method makes the best use of the out-of-event data and achieves good results.
    bibtex: >
      @inproceedings{nguyen-et-al-icwsm-17,
       abstract = {The role of social media, in particular microblogging platforms such as Twitter, as a conduit for actionable and tactical information during disasters is increasingly acknowledged. However, time-critical analysis of big crisis data on social media streams brings challenges to machine learning techniques, especially the ones that use supervised learning. The scarcity of labeled data, particularly in the early hours of a crisis, delays the learning process. Existing classification methods require a significant amount of labeled data specific to a particular event for training plus a lot of feature engineering to achieve best results. In this work, we introduce neural network based classification methods for identifying useful tweets during a crisis situation. At the onset of a disaster when no labeled data is available, our proposed method makes the best use of the out-of-event data and achieves good results.},
       address = {Montr{\'{e}}al, Qu{\'{e}}bec, Canada},
       author = {Dat Nguyen and Kamela Ali Al Mannai and Shafiq Joty and Hassan Sajjad and Muhammad Imran and Prasenjit Mitra},
       booktitle = {In Proceedings of the Eleventh International Conference on Web and Social
      Media},
       link = {papers/nguyen-et-al-icwsm-17.pdf},
       month = {May},
       pages = {632--635},
       publisher = {AAAI},
       series = {ICWSM'17},
       title = {Robust Classification of Crisis-Related Data on Social Networks Using Convolutional Neural Networks},
       year = {2017}
      }
      
      
  -
    layout: paper
    paper-type: inproceedings #changes display of reference in paper list
    year: 2017
    selected: no
    title: >
      CQAVis: Visual Text Analytics for Community Question Answering
    authors: Enamul Hoque, Shafiq Joty, Lluís Màrquez, and Giuseppe Carenini
    id: hoque-et-al-iui-17
    img: hoque-et-al-iui-17-fig
    slides: media/hoque-et-al-iui-17.pdf
    code: #e.g. github.com/project
    errata: #if you have errata, insert here
    venue: conference
    pages: 161-172
    booktitle: >
      Proceedings of the 2017 international conference on Intelligent user interfaces (IUI'17)
    doc-url: http://dl.acm.org/citation.cfm?id=3025210
    abstract: >
      Community question answering (CQA) forums can provide effective means for sharing information and addressing a user's information needs about particular topics. However, many such online forums are not moderated, resulting in many low quality and redundant comments, which makes it very challenging for users to find the appropriate answers to their questions. In this paper, we apply a user-centered design approach to develop a system, CQAVis, which supports users in identifying high quality comments and get their questions answered. Informed by the user's requirements, the system combines both text analytics and interactive visualization techniques together in a synergistic way. Given a new question posed by the user, the text analytic module automatically finds relevant answers by exploring existing related questions and the comments within their threads. Then the visualization module presents the search results to the user and supports the exploration of related comments. We have evaluated the system in the wild by deploying it within a CQA forum among thousands of real users. Through the online study, we gained deeper insights about the potential utility of the system, as well as learned generalizable lessons for designing visual text analytics systems for the domain of CQA forums.
    bibtex: >
      @inproceedings{hoque-et-al-iui-17,
       abstract = {Community question answering (CQA) forums can provide effective means for sharing information and addressing a user's information needs about particular topics. However, many such online forums are not moderated, resulting in many low quality and redundant comments, which makes it very challenging for users to find the appropriate answers to their questions. In this paper, we apply a user-centered design approach to develop a system, CQAVis, which supports users in identifying high quality comments and get their questions answered. Informed by the user's requirements, the system combines both text analytics and interactive visualization techniques together in a synergistic way. Given a new question posed by the user, the text analytic module automatically finds relevant answers by exploring existing related questions and the comments within their threads. Then the visualization module presents the search results to the user and supports the exploration of related comments. We have evaluated the system in the wild by deploying it within a CQA forum among thousands of real users. Through the online study, we gained deeper insights about the potential utility of the system, as well as learned generalizable lessons for designing visual text analytics systems for the domain of CQA forums.},
       address = {Limassol, Cyprus},
       author = {Enamul Hoque and Shafiq Joty and Lluís Màrquez and Giuseppe Carenini},
       booktitle = {Proceedings of the 2017 international conference on Intelligent user interfaces},
       link = {http://dl.acm.org/citation.cfm?id=3025210},
       pages = {161--172},
       publisher = {ACM},
       series = {IUI'17},
       title = {CQAVis: Visual Text Analytics for Community Question Answering},
       year = {2017}
      }
      
      
