---
abstract: 'Most state-of-the-art neural machine translation systems, despite being
  different in architectural skeletons (e.g. recurrence, convolutional), share an
  indispensable feature: the Attention. However, most existing attention methods are
  token-based and ignore the importance of phrasal alignments, the key ingredient
  for the success of phrase-based statistical machine translation. In this paper,
  we propose novel phrase-based attention methods to model n-grams of tokens as attention
  entities. We incorporate our phrase-based attentions into the recently proposed
  Transformer network, and demonstrate that our approach yields improvements of 1.3
  BLEU for English-to-German and 0.5 BLEU for German-to-English translation tasks
  on WMT newstest2014 using WMT''16 training data.

  '
authors: Phi Xuan, and Shafiq Joty
bibtex: "@article{phi-joty-iclr-19,\n abstract = {Most state-of-the-art neural machine\
  \ translation systems, despite being different in architectural skeletons (e.g.\
  \ recurrence, convolutional), share an indispensable feature: the Attention. However,\
  \ most existing attention methods are token-based and ignore the importance of phrasal\
  \ alignments, the key ingredient for the success of phrase-based statistical machine\
  \ translation. In this paper, we propose novel phrase-based attention methods to\
  \ model n-grams of tokens as attention entities. We incorporate our phrase-based\
  \ attentions into the recently proposed Transformer network, and demonstrate that\
  \ our approach yields improvements of 1.3 BLEU for English-to-German and 0.5 BLEU\
  \ for German-to-English translation tasks on WMT newstest2014 using WMT'16 training\
  \ data.},\n author = {Phi Xuan Nguyen and Shafiq Joty},\n issue = {},\n journal\
  \ = {arxiv},\n link = {https://arxiv.org/abs/1810.03444},\n pages = {},\n publisher\
  \ = {},\n title = {Phrase-Based Attentions},\n year = {2018}\n}\n"
code: null
doc-url: https://arxiv.org/abs/1810.03444
errata: null
id: phi-joty-iclr-19
img: phi-joty-iclr-19-fig
journal: arxiv
layout: singlepaper
pages: null
paper-type: article
picture: shafiq
selected: true
slides: null
title: 'Phrase-Based Attentions

  '
venue: journal
year: 2018
---

{% include singlepaper.html paper=page %}