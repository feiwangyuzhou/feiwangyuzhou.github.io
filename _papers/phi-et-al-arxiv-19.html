---
abstract: 'A common approach to improve neural machine translation is to invent new
  architectures. However, the research process of designing and refining such new
  models is often exhausting. Another approach is to resort to huge extra monolingual
  data to conduct semi-supervised training, like back-translation. But extra monolingual
  data is not always available, especially for low resource languages. In this paper,
  we propose to diversify the available training data by using multiple forward and
  backward peer models to augment the original training dataset. Our method does not
  require extra data like back-translation, nor additional computations and parameters
  like using pretrained models. Our data diversification method achieves state-of-the-art
  BLEU score of 30.7 in the WMT''14 English-German task. It also consistently and
  substantially improves translation quality in 8 other translation tasks: 4 IWSLT
  tasks (English-German and English-French) and 4 low-resource translation tasks (English-Nepali
  and English-Sinhala).

  '
authors: Xuan-Phi Nguyen, Shafiq Joty, Wu Kui, and Ai Ti
bibtex: "@article{phi-et-al-arxiv-19,\n abstract = {A common approach to improve neural\
  \ machine translation is to invent new architectures. However, the research process\
  \ of designing and refining such new models is often exhausting. Another approach\
  \ is to resort to huge extra monolingual data to conduct semi-supervised training,\
  \ like back-translation. But extra monolingual data is not always available, especially\
  \ for low resource languages. In this paper, we propose to diversify the available\
  \ training data by using multiple forward and backward peer models to augment the\
  \ original training dataset. Our method does not require extra data like back-translation,\
  \ nor additional computations and parameters like using pretrained models. Our data\
  \ diversification method achieves state-of-the-art BLEU score of 30.7 in the WMT'14\
  \ English-German task. It also consistently and substantially improves translation\
  \ quality in 8 other translation tasks: 4 IWSLT tasks (English-German and English-French)\
  \ and 4 low-resource translation tasks (English-Nepali and English-Sinhala).},\n\
  \ author = {Xuan-Phi Nguyen and Shafiq Joty and Wu Kui and Ai Ti Aw},\n issue =\
  \ {},\n journal = {arXiv (* not peer reviewed)},\n link = {https://arxiv.org/abs/1911.01986},\n\
  \ pages = {},\n publisher = {arXiv.org},\n title = {Data Diversification: An Elegant\
  \ Strategy for Neural Machine Translation},\n year = {2020}\n}\n"
code: null
doc-url: https://arxiv.org/abs/1911.01986
errata: null
id: phi-et-al-arxiv-19
img: phi-et-al-arxiv-19-fig
journal: arXiv (* not peer reviewed)
layout: singlepaper
pages: null
paper-type: article
picture: shafiq
selected: true
slides: null
title: 'Data Diversification: An Elegant Strategy for Neural Machine Translation

  '
venue: journal
year: 2020
---

{% include singlepaper.html paper=page %}