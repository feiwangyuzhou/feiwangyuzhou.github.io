@article{nguyen2020multiagent,
    title={Multi-Agent Cross-Translated Diversification for Unsupervised Machine Translation},
    author={Xuan-Phi Nguyen and Shafiq Joty and Wu Kui and Ai Ti Aw},
    journal = {arXiv (* not peer reviewed)},
    publisher={arXiv.org},
    issue={},
    pages={xx--xx},
    year={2020},
    url = {https://arxiv.org/abs/2006.02163},
    abstract={Recent unsupervised machine translation (UMT) systems usually employ three main principles: initialization, language modeling and iterative back-translation, though they may apply these principles differently. This work introduces another component to this framework: Multi-Agent Cross-translated Diversification (MACD). The method trains multiple UMT agents and then translates monolingual data back and forth using non-duplicative agents to acquire synthetic parallel data for supervised MT. MACD is applicable to all previous UMT approaches. In our experiments, the technique boosts the performance for some commonly used UMT methods by 1.5-2.0 BLEU. In particular, in WMT'14 English-French, WMT'16 German-English and English-Romanian, MACD outperforms cross-lingual masked language model pretraining by 2.3, 2.2 and 1.6 BLEU, respectively. It also yields 1.5-3.3 BLEU improvements in IWSLT English-French and English-German translation tasks. Through extensive experimental analyses, we show that MACD is effective because it embraces data diversity while other similar variants do not.},
}


















@article{tan-et-al-arxiv-20,
  title="{Mind Your Inflections! Improving NLP for Non-Standard English with Base-Inflection Encoding}",
  author={Samson Tan and Shafiq Joty and Lav R. Varshney and Min-Yen Kan},
  journal = {arXiv (* not peer reviewed)},
  publisher={arXiv.org},
  issue={},
  pages={},
  year={2020},
  url = {https://arxiv.org/abs/2004.14870},
  abstract={Morphological inflection is a process of word formation where base words are modified to express different grammatical categories such as tense, case, voice, person, or number. World Englishes, such as Colloquial Singapore English (CSE) and African American Vernacular English (AAVE), differ from Standard English dialects in inflection use. Although comprehension by human readers is usually unimpaired by non-standard inflection use, NLP systems are not so robust. We introduce a new Base-Inflection Encoding of English text that is achieved by combining linguistic and statistical techniques. Fine-tuning pre-trained NLP models for downstream tasks under this novel encoding achieves robustness to non-standard inflection use while maintaining performance on Standard English examples. Models using this encoding also generalize better to non-standard dialects without explicit training. We suggest metrics to evaluate tokenizers and extensive model-independent analyses demonstrate the efficacy of the encoding when used together with data-driven subword tokenizers.},
}



@article{jwala-et-al-arxiv-20,
  title="{Can Your Context-Aware MT System Pass the DiP Benchmark Tests? : Evaluation Benchmarks for Discourse Phenomena in Machine Translation}",
  author={Prathyusha Jwalapuram and Barbara Rychalska and Shafiq Joty and Dominika Basaj},
  journal = {arXiv (* not peer reviewed)},
  publisher={arXiv.org},
  issue={},
  pages={},
  year={2020},
  url = {https://arxiv.org/abs/2004.14607},
  abstract={Despite increasing instances of machine translation (MT) systems including contextual information, the evidence for translation quality improvement is sparse, especially for discourse phenomena. Popular metrics like BLEU are not expressive or sensitive enough to capture quality improvements or drops that are minor in size but significant in perception. We introduce the first of their kind MT benchmark datasets that aim to track and hail improvements across four main discourse phenomena: anaphora, lexical consistency, coherence and readability, and discourse connective translation. We also introduce evaluation methods for these tasks, and evaluate several baseline MT systems on the curated datasets. Surprisingly, we find that existing context-aware models do not improve discourse-related translations consistently across languages and phenomena.},
}

@article{mohiuddin-et-al-arxiv-20,
  title="{LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction Through Non-Linear Mapping in Latent Space}",
  author={Tasnim Mohiuddin and M Saiful Bari and Shafiq Joty},
  journal = {arXiv (* not peer reviewed)},
  publisher={arXiv.org},
  issue={},
  pages={},
  year={2020},
  url = {https://arxiv.org/abs/2004.13889},
  abstract={Most of the successful and predominant methods for bilingual lexicon induction (BLI) are mapping-based, where a linear mapping function is learned with the assumption that the word embedding spaces of different languages exhibit similar geometric structures (i.e., approximately isomorphic). However, several recent studies have criticized this simplified assumption showing that it does not hold in general even for closely related languages. In this work, we propose a novel semi-supervised method to learn cross-lingual word embeddings for BLI. Our model is independent of the isomorphic assumption and uses nonlinear mapping in the latent space of two independently trained auto-encoders. Through extensive experiments on fifteen (15) different language pairs (in both directions) comprising resource-rich and low-resource languages from two different datasets, we demonstrate that our method outperforms existing models by a good margin. Ablation studies show the importance of different model components and the necessity of non-linear mapping.},
}


@article{yue-et-al-arxiv-20,
  title="{VD-BERT: A Unified Vision and Dialog Transformer with BERT}",
  author={Yue Wang and Shafiq Joty and Michael R. Lyu and Irwin King and Caiming Xiong and Steven C.H. Hoi},
  journal = {arXiv (* not peer reviewed)},
  publisher={arXiv.org},
  issue={},
  pages={},
  year={2020},
  url = {https://arxiv.org/abs/2004.13278},
  abstract={Visual dialog is a challenging vision-language task, where a dialog agent needs to answer a series of questions through reasoning on the image content and dialog history. Prior work has mostly focused on various attention mechanisms to model such intricate interactions. By contrast, in this work, we propose VD-BERT, a simple yet effective framework of unified vision-dialog Transformer that leverages the pretrained BERT language models for Visual Dialog tasks. The model is unified in that (1) it captures all the interactions between the image and the multi-turn dialog using a single-stream Transformer encoder, and (2) it supports both answer ranking and answer generation seamlessly through the same architecture. More crucially, we adapt BERT for the effective fusion of vision and dialog contents via visually grounded training. Without the need of pretraining on external vision-language data, our model yields new state of the art, achieving the top position in both single-model and ensemble settings (74.54 and 75.35 NDCG scores) on the visual dialog leaderboard.},
}

@article{bari-et-al-arxiv-20,
  title="{MultiMix: A Robust Data Augmentation Strategy for Cross-Lingual NLP}",
  author={M Saiful Bari and Tasnim Mohiuddin and Shafiq Joty},
  journal = {arXiv (* not peer reviewed)},
  publisher={arXiv.org},
  issue={},
  pages={},
  year={2020},
  url = {https://arxiv.org/abs/2004.13889},
  abstract={Transfer learning has yielded state-of-the-art results in many supervised natural language processing tasks. However, annotated data for every target task in every target language is rare, especially for low-resource languages. In this work, we propose MultiMix, a novel data augmentation method for semi-supervised learning in zero-shot transfer learning scenarios. In particular, MultiMix targets to solve cross-lingual adaptation problems from a source (language) distribution to an unknown target (language) distribution assuming it has no training labels in the target language task. In its heart, MultiMix performs simultaneous self-training with data augmentation and unsupervised sample selection. To show its effectiveness, we have performed extensive experiments on zero-shot transfers for cross-lingual named entity recognition (XNER) and natural language inference (XNLI). Our experiments show sizeable improvements in both tasks outperforming the baselines by a good margin.},
}

@article{mohiuddin-coh-et-al-arxiv-20,
  title="{CohEval: Benchmarking Coherence Models}",
  author={Tasnim Mohiuddin and Prathyusha Jwalapuram and Xiang Lin and Shafiq Joty},
  journal = {arXiv (* not peer reviewed)},
  publisher={arXiv.org},
  issue={},
  pages={},
  year={2020},
  url = {https://arxiv.org/abs/2004.13889},
  abstract={Although coherence modeling has come a long way in developing novel models, their evaluation on downstream applications has largely been neglected. With the advancements made by neural approaches in applications such as machine translation, text summarization and dialogue systems, the need for standard coherence evaluation is now more crucial than ever. In this paper, we propose to benchmark coherence models on a number of synthetic and downstream tasks. In particular, we evaluate well-known traditional and neural coherence models on sentence ordering tasks, and also on three downstream applications including coherence evaluation for machine translation, summarization and next utterance prediction. We also show model produced rankings for pre-trained language model outputs as another use-case. Our results demonstrate a weak correlation between the model performances in the synthetic tasks and the downstream applications, motivating alternate evaluation methods for coherence models. This work has led us to create a leaderboard to foster further research in coherence modeling.},
}


