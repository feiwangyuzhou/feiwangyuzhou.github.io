%% Saved with string encoding Unicode (UTF-8)


@InProceedings{dat-joty:2017,
  author    = {Nguyen, Dat and Joty, Shafiq},
  title     = {A Neural Local Coherence Model},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL-2017)},
  month     = {August},
  year      = {2017},
  series    = {ACL '17},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {xx--xx},
  url       = {http://alt.qcri.org/~sjoty/paper/local_coh_acl17.pdf},
  abstract = {We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.}
}




@article{Shafiq_discoMT17,
  title="{Discourse Structure in Machine Translation Evaluation}",
  author={Shafiq Joty and Guzm\'{a}n, Francisco and Màrquez, Lluís and Preslav Nakov},
  journal = {Computational Linguistics},
  volume={xx:x},
  publisher={MIT Press},
  pages={},
  url = {discomteval.pdf},
  year={2017},
  abstract={In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all- subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple linear combination with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment- and at the system-level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DISCOTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular, we show that (i) all aspects of the RST tree are relevant, (ii) nuclearity is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality.}
}


@article{Shafiq_da_CL16,
  title="{Domain Adaptation Using Neural Network Joint Model}",
  author={Shafiq Joty and Nadir Durrani and Hassan Sajjad and Ahmed Abdelali},
  journal = {Computer Speech & Language},
  volume={45},
  publisher={Elsevier},
  pages={161-179},
  year={2017},
  issn = {0885-2308},
  doi = {https://doi.org/10.1016/j.csl.2016.12.006},
  url = {http://www.sciencedirect.com/science/article/pii/S0885230816301474},
  abstract={We explore neural joint models for the task of domain adaptation in machine translation in two ways: (i) we apply state-of-the-art domain adaptation techniques, such as mixture modelling and data selection using the recently proposed Neural Network Joint Model (NNJM) (Devlin et al., 2014); (ii) we propose two novel approaches to perform adaptation through instance weighting and weight readjustment in the NNJM framework. In our first approach, we propose a pair of models called Neural Domain Adaptation Models (NDAM) that minimizes the cross entropy by regularizing the loss function with respect to in-domain (and optionally to out-domain) model. In the second approach, we present a set of Neural Fusion Models (NFM) that combines the in- and the out-domain models by readjusting their parameters based on the in-domain data.
We evaluated our models on the standard task of translating English-to-German and Arabic-to-English TED talks. The NDAM models achieved better perplexities and modest BLEU improvements compared to the baseline NNJM, trained either on in-domain or on a concatenation of in- and out-domain data. On the other hand, the NFM models obtained significant improvements of up to +0.9 and +0.7 BLEU points, respectively. We also demonstrate improvements over existing adaptation methods such as instance weighting, phrasetable fill-up, linear and log-linear interpolations.}
}

@InProceedings{guzman-EtAl:2014:P14-1,
  author    = {Guzm\'{a}n, Francisco  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav},
  title     = {Using Discourse Structure Improves Machine Translation Evaluation},
  booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics ({ACL}'14)},
  month     = {June},
  year      = {2014},
  address   = {Baltimore, Maryland, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {687--698},
  url       = {http://www.aclweb.org/anthology/P/P14/P14-1065},
  Abstract = { We present experiments in using discourse structure for improving machine translation evaluation. We first design two discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory. Then, we show that these measures can help improve a number of existing machine translation evaluation metrics both at the segmentand at the system-level. Rather than proposing a single new metric, we show that discourse information is complementary to the state-of-the-art evaluation metrics, and thus should be taken into account in the development of future richer evaluation metrics.}
}

@InProceedings{joty-EtAl:2014:W14-33,
  author    = {Joty, Shafiq  and  Guzm\'{a}n, Francisco  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav},
  title     = {DiscoTK: Using Discourse Structure for Machine Translation Evaluation},
  booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation ({WMT}'14)},
  month     = {June},
  year      = {2014},
  address   = {Baltimore, Maryland, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {402--408},
  url       = {http://www.aclweb.org/anthology/W/W14/W14-3352},
  Abstract = {We present novel automatic metrics for machine translation evaluation that use discourse structure and convolution kernels to compare the discourse tree of an automatic translation with that of the human reference. We experiment with five transformations and augmentations of a base discourse tree representation based on the rhetorical structure theory, and we combine the kernel scores for each of them into a single score. Finally, we add other metrics from the ASIYA MT evaluation toolkit, and we tune the weights of the combination on actual human judgments. Experiments on the WMT12 and WMT13 metrics shared task datasets show correlation with human judgments that outperforms what the best systems that participated in these years achieved, both at the segment and at the system level.}
}

@InProceedings{guzman-EtAl:2014:EMNLP2014,
  author    = {Guzm\'{a}n, Francisco  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Moschitti, Alessandro  and  Nakov, Preslav  and  Nicosia, Massimo},
  title     = {Learning to Differentiate Better from Worse Translations},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}'14)},
  month     = {October},
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  pages     = {214--220},
  url       = {http://www.aclweb.org/anthology/D14-1027},
  Abstract = {We present a pairwise learning-to-rank approach to machine translation evaluation that learns to differentiate better from worse translations in the context of a given reference. We integrate several layers of linguistic information encapsulated in tree-based structures, making use of both the reference and the system output simultaneously, thus bringing our ranking closer to how humans evaluate translations. Most importantly, instead of deciding upfront which types of features are important, we use the learning framework of preference re-ranking kernels to learn the features automatically. The evaluation results show that learning in the proposed framework yields better correlation with humans than computing the direct similarity over the same type of structures. Also, we show our structural kernel learning (SKL) can be a general framework for MT evaluation, in which syntactic and semantic information can be naturally incorporated.}
}






@InProceedings{guzman2015-ACL,
  author    = {Guzm\'{a}n, Francisco  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav },
  title     = {Pairwise Neural Machine Translation Evaluation},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and The 7th International Joint Conference of the Asian
            Federation of Natural Language Processing ({ACL}'15)},
  month     = {July},
  year      = {2015},
  address   = {Beijing, China},
  publisher = {Association for Computational Linguistics},
  pages     = {805--814},
  url       = {http://www.aclweb.org/anthology/P15-1078},
  Abstract = {We present a novel framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is compacted into relatively small distributed vector representations, and fed into a multi-layer neural network that models the interaction between each of the hypotheses and the reference, as well as between the two hypotheses. These compact representations are in turn based on word and sentence embeddings, which are learned using neural networks. The framework is flexible, allows for efficient learning and classification, and yields correlation with humans that rivals the state of the art.}
}



@article{GuzmanCSL2016,
title = {Machine translation evaluation with neural networks},
journal = {Computer Speech & Language},
year = {2016},
issn = {0885-2308},
doi = {http://dx.doi.org/10.1016/j.csl.2016.12.005},
url = {http://www.sciencedirect.com/science/article/pii/S0885230816301693},
author = {Guzm\'{a}n, Francisco  and Joty, Shafiq  and Màrquez, Lluís  and Nakov, Preslav },
pages = {180--200},
abstract = {Abstract We present a framework for machine translation evaluation using neural networks in a pairwise setting,
where the goal is to select the better translation from a pair of hypotheses, given the reference translation.
In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses
is embedded into compact distributed vector representations, and fed into a multi-layer neural network that
models nonlinear interactions between each of the hypotheses and the reference, as well as between the two hypotheses.
We experiment with the benchmark datasets from the \{WMT\} Metrics shared task, on which we obtain the best results published so far,
with the basic network configuration.
We also perform a series of experiments to analyze and understand the contribution of the different components of the network.
We evaluate variants and extensions, including fine-tuning of the semantic embeddings, and sentence-based representations modeled with
convolutional and recurrent neural networks. In summary, the proposed framework is flexible and generalizable,
allows for efficient learning and scoring, and provides an \{MT\} evaluation metric that correlates with human judgments,
and is on par with the state of the art. }
}

