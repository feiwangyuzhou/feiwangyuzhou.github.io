


%% Saved with string encoding Unicode (UTF-8)










@phdthesis{guzman-thesis:2011,
Author = {Guzm{\'a}n, Francisco },
Title = {The Impact of Statistical Word Alignment Quality and Structure in Phrase Based Statistical Machine Translation},
Year = {2011},
Month = {December},
school = {Instituto Tecnológico y de Estudios Superiores de Monterrey, Campus Monterrey},
Abstract = { Statistical Word Alignments represent lexical word-to-word translations between source and target language sentences. They are considered the starting point for many state of the art Statistical Machine Translation (SMT) systems. In phrase-based systems, word alignments are loosely linked to the translation model. Despite the improvements reached in word alignment quality, there has been a modest improvement in the end-to-end translation. Until recently, little or no attention was paid to the structural characteristics of word-alignments (e.g. unaligned words) and their impact in further stages of the phrase-based SMT pipeline. A better understanding of the relationship between word alignment and the entailing processes will help to identify the variables across the pipeline that most influence translation performance and can be controlled by modifying word alignment’s characteristics.
In this dissertation, we perform an in-depth study of the impact of word alignments at different stages of the phrase-based statistical machine translation pipeline, namely word alignment, phrase extraction, phrase scoring and decoding. Moreover, we establish a multivariate prediction model for different variables of word alignments, phrase tables and translation hypotheses. Based on those models, we identify the most important alignment variables and propose two alternatives to provide more control over alignment structure and thus improve SMT. Our results show that using alignment structure into decoding, via alignment gap features yields significant improvements, specially in situations where translation data is limited.
During the development of this dissertation we discovered how different characteristics of the alignment impact Machine Translation. We observed that while good quality alignments yield good phrase-pairs, the consolidation of a translation model is dependent on the alignment structure, not quality. Human-alignments are more dense than the computer generated counterparts, which trend to be more sparse and precision-oriented. Trying to emulate human-like alignment structure resulted in poorer systems, because the resulting translation models trend to be more compact and lack translation options. On the other hand, more translation options, even if they are noisier, help to improve the quality of the translation. This is due to the fact that translation does not rely only on the translation model, but also other factors that help to discriminate the noise from bad translations (e.g. the language model). Lastly, when we provide the decoder with features that help it to make more `informed decisions'' we observe a clear improvement in translation quality. This was specially true for the discriminative alignments which inherently leave more unaligned words. The result is more evident in low-resource settings where having larger translation lexicons represent more translation options. Using simple features to help the decoder discriminate translation hypotheses, clearly showed consistent improvements.}}




@InProceedings{guzman-EtAl:2014:P14-1,
  author    = {Guzm\'{a}n, Francisco  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav},
  title     = {Using Discourse Structure Improves Machine Translation Evaluation},
  booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics ({ACL}'14)},
  month     = {June},
  year      = {2014},
  address   = {Baltimore, Maryland, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {687--698},
  url       = {http://www.aclweb.org/anthology/P/P14/P14-1065},
  Abstract = { We present experiments in using discourse structure for improving machine translation evaluation. We first design two discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory. Then, we show that these measures can help improve a number of existing machine translation evaluation metrics both at the segmentand at the system-level. Rather than proposing a single new metric, we show that discourse information is complementary to the state-of-the-art evaluation metrics, and thus should be taken into account in the development of future richer evaluation metrics.}
}

@InProceedings{joty-EtAl:2014:W14-33,
  author    = {Joty, Shafiq  and  Guzm\'{a}n, Francisco  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav},
  title     = {DiscoTK: Using Discourse Structure for Machine Translation Evaluation},
  booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation ({WMT}'14)},
  month     = {June},
  year      = {2014},
  address   = {Baltimore, Maryland, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {402--408},
  url       = {http://www.aclweb.org/anthology/W/W14/W14-3352},
  Abstract = {We present novel automatic metrics for machine translation evaluation that use discourse structure and convolution kernels to compare the discourse tree of an automatic translation with that of the human reference. We experiment with five transformations and augmentations of a base discourse tree representation based on the rhetorical structure theory, and we combine the kernel scores for each of them into a single score. Finally, we add other metrics from the ASIYA MT evaluation toolkit, and we tune the weights of the combination on actual human judgments. Experiments on the WMT12 and WMT13 metrics shared task datasets show correlation with human judgments that outperforms what the best systems that participated in these years achieved, both at the segment and at the system level.}
}

@InProceedings{guzman-EtAl:2014:EMNLP2014,
  author    = {Guzm\'{a}n, Francisco  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Moschitti, Alessandro  and  Nakov, Preslav  and  Nicosia, Massimo},
  title     = {Learning to Differentiate Better from Worse Translations},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}'14)},
  month     = {October},
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  pages     = {214--220},
  url       = {http://www.aclweb.org/anthology/D14-1027},
  Abstract = {We present a pairwise learning-to-rank approach to machine translation evaluation that learns to differentiate better from worse translations in the context of a given reference. We integrate several layers of linguistic information encapsulated in tree-based structures, making use of both the reference and the system output simultaneously, thus bringing our ranking closer to how humans evaluate translations. Most importantly, instead of deciding upfront which types of features are important, we use the learning framework of preference re-ranking kernels to learn the features automatically. The evaluation results show that learning in the proposed framework yields better correlation with humans than computing the direct similarity over the same type of structures. Also, we show our structural kernel learning (SKL) can be a general framework for MT evaluation, in which syntactic and semantic information can be naturally incorporated.}
}






@InProceedings{guzman2015-ACL,
  author    = {Guzm\'{a}n, Francisco  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Nakov, Preslav },
  title     = {Pairwise Neural Machine Translation Evaluation},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and The 7th International Joint Conference of the Asian
            Federation of Natural Language Processing ({ACL}'15)},
  month     = {July},
  year      = {2015},
  address   = {Beijing, China},
  publisher = {Association for Computational Linguistics},
  pages     = {805--814},
  url       = {http://www.aclweb.org/anthology/P15-1078},
  Abstract = {We present a novel framework for machine translation evaluation using neural networks in a pairwise setting, where the goal is to select the better translation from a pair of hypotheses, given the reference translation. In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses is compacted into relatively small distributed vector representations, and fed into a multi-layer neural network that models the interaction between each of the hypotheses and the reference, as well as between the two hypotheses. These compact representations are in turn based on word and sentence embeddings, which are learned using neural networks. The framework is flexible, allows for efficient learning and classification, and yields correlation with humans that rivals the state of the art.}
}

@InProceedings{dat-joty:2017,
  author    = {Dat Tien Nguyen  and  Shafiq Joty},
  title     = {A Neural Local Coherence Model},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = {August},
  year      = {2017},
  series = {ACL '17},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {(to appear)}
%  url       = {http://www.aclweb.org/anthology/P16-1165}
abstract = {We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.} 
}


@article{GuzmanCSL2016,
title = {Machine translation evaluation with neural networks},
journal = {Computer Speech & Language},
year = {2016},
issn = {0885-2308},
doi = {http://dx.doi.org/10.1016/j.csl.2016.12.005},
url = {http://www.sciencedirect.com/science/article/pii/S0885230816301693},
author = {Guzm\'{a}n,Francisco  and Joty, Shafiq  and Màrquez,Lluís  and Nakov, Preslav },
abstract = {Abstract We present a framework for machine translation evaluation using neural networks in a pairwise setting,
where the goal is to select the better translation from a pair of hypotheses, given the reference translation.
In this framework, lexical, syntactic and semantic information from the reference and the two hypotheses
is embedded into compact distributed vector representations, and fed into a multi-layer neural network that
models nonlinear interactions between each of the hypotheses and the reference, as well as between the two hypotheses.
We experiment with the benchmark datasets from the \{WMT\} Metrics shared task, on which we obtain the best results published so far,
with the basic network configuration.
We also perform a series of experiments to analyze and understand the contribution of the different components of the network.
We evaluate variants and extensions, including fine-tuning of the semantic embeddings, and sentence-based representations modeled with
convolutional and recurrent neural networks. In summary, the proposed framework is flexible and generalizable,
allows for efficient learning and scoring, and provides an \{MT\} evaluation metric that correlates with human judgments,
and is on par with the state of the art. }
}
