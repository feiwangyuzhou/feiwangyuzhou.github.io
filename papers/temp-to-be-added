@article{joty-cl-18,
  title="{NeuralGrid: Entity-based Neural Coherence Models for Monologue and Conversation}",
  author={Shafiq Joty and Dat Nguyen and Basma Boussaha and Maarten de-Rijke},
  journal = {Computational Linguistics},
  issue={},
  publisher={MIT Press},
  pages={(Working paper)},
  url = {},
  year={2018},
  abstract={We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions  along with entity-specific features without loosing generalization, thanks to the power of  distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. We further extend our approach to model discourse coherence in asynchronous conversation (e.g., forum, email) by incorporating the conversational structure into the grid representation. Our evaluation on the standard coherence assessment tasks in monologue demonstrates that our model achieves state of the art results outperforming existing models by a good margin. The evaluation on a forum dataset shows the benefit of modeling conversational structure. A further evaluation demonstrates the utility of our neural coherence model for the task of thread reconstruction in forum conversation.
}
}

@InProceedings{saha-joty-hasan-kdd-18,
  author    = {Tanay Saha and Shafiq Joty and Mohammad Hasan},
  title     = {MCATS: Models for Capturing Temporal Smoothness in Evolving Network for Learning Latent Representation of Nodes},
  booktitle = {Knowledge Discovery and Data Mining},
  month     = {September},
  year      = {2018},
  series    = {(under review in KDD'18)},
  address   = {},
  publisher = {ACM},
  pages     = {xx -- xx},
  url       = {},
  abstract = {}
}



@InProceedings{aggarwal-et-al-kdd-18,
  author = {Karan Aggarwal and Shafiq Joty and Luis F Luque and Jaideep Srivastava},
  title = {Unsupervised Representation Learning for Activity Time-Series},
  booktitle = {Knowledge Discovery and Data Mining},
  year      = {2018},
  series    = {(under review in KDD'18)},
  address   = {},
  publisher = {ACM},
  pages     = {xx -- xx},
  url       = {https://arxiv.org/abs/1712.09527},
  abstract  = {Physical activity and sleep play a major role in the prevention and management of many chronic conditions. It is not a trivial task to understand their impact on chronic conditions. Currently, data from electronic health records (EHRs), sleep lab studies, and activity/sleep logs are used. The rapid increase in the popularity of wearable health devices provides a significant new data source, making it possible to track the user's lifestyle real-time through web interfaces, both to consumer as well as their healthcare provider, potentially. However, at present there is a gap between lifestyle data (e.g., sleep, physical activity) and clinical outcomes normally captured in EHRs. This is a critical barrier for the use of this new source of signal for healthcare decision making. Applying deep learning to wearables data provides a new opportunity to overcome this barrier.To address the problem of the unavailability of clinical data from a major fraction of subjects and unrepresentative subject populations, we propose a novel unsupervised (task-agnostic) time-series representation learning technique called act2vec. act2vec learns useful features by taking into account the co-occurrence of activity levels along with periodicity of human activity patterns. The learned representations are then exploited to boost the performance of disorder-specific supervised learning models. Furthermore, since many disorders are often related to each other, a phenomenon referred to as co-morbidity, we use a multi-task learning framework for exploiting the shared structure of disorder inducing life-style choices partially captured in the wearables data. Empirical evaluation using actigraphy data from 4,124 subjects shows that our proposed method performs and generalizes substantially better than the conventional time-series symbolic representational methods and task-specific deep learning models.}
  }
